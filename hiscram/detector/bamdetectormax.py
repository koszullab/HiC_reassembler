from abc import abstractproperty
from shutil import register_unpack_format
import pysam as ps
import numpy as np
import pandas as pd
import pyfastx
from hiscram.detector.bam_functions import bam_region_coverage, bam_region_read_ends, check_gen_sort_index
from os.path import join

class Bamdetectormax(object):
    """
    Class allowing the detection of breakpoints at base pair precision using alignment files
    generated by the aligner. The class doesn't use the SA tag for clipped reads (bowtie2 doesn't use this flag).

    Attributes
    ----------
    chrom: str
        Chromosome (or contig) on which the detection will be done.

    binsize: int
        Size of the bins of the contact map used for the detection.

    for_bam: str
    rev_bam: str
        Paths to the alignement files.
    
    ref_seq: str
        Path to the reference sequence on which the reads are aligned.
        
    tmpdir: str
        Path to the temporary directory
    """

    def __init__(self, chrom, binsize, for_bam:str, rev_bam:str, ref_seq:str = None, tmpdir:str="./tmpdir"):
        self.chrom = chrom
        self.binsize = binsize
        self.tmpdir = tmpdir
        self.bamfile_for = ps.AlignmentFile(for_bam)
        self.bamfile_rev = ps.AlignmentFile(rev_bam)
        
        if ref_seq is not None:
            self.seq = pyfastx.Fasta(str(ref_seq))
        else:
            self.seq = None
        try:
            self.load_detect()
        except:
            pass
    
    def load_detect(self):
        """
        Load zones which are be detected as structural variations on the Hi-C matrix.
        """
        self.delim = np.load(join(self.tmpdir, "coords_delim.npy"))
        self.SVdetected = np.load(join(self.tmpdir, "SV_index.npy"))
    
    def create_clusters(self):
        """
        Created the clusters corresponding to consecutive positives yield by the matrix detector.
        """
        self.clusters = []
        for p in range(len(self.SVdetected)):
            if len(self.clusters) != 0 and self.SVdetected[p] == self.clusters[-1][-1] + 1:
                self.clusters[-1].append(self.SVdetected[p])
            else:
                self.clusters.append([self.SVdetected[p]])


    def fetch_coverage(self, region:str):
        """
        Retrieve the total read coverage.
        """
        bam_sorted_for = check_gen_sort_index(self.bamfile_for)
        bam_sorted_rev = check_gen_sort_index(self.bamfile_rev)
        coverage_for = bam_region_coverage(str(bam_sorted_for),region)
        coverage_rev = bam_region_coverage(str(bam_sorted_rev),region)
        coverage_total = coverage_for + coverage_rev
        return coverage_total
    
    def fetch_clipped(self, region:str):
        """
        Retrieve the coverage of clipped reads.
        """
        bam_sorted_for = check_gen_sort_index(self.bamfile_for)
        bam_sorted_rev = check_gen_sort_index(self.bamfile_rev)
        start_arr_clip_for, end_arr_clip_for = bam_region_read_ends(str(bam_sorted_for), region, side="both", clipped=True)
        start_arr_clip_rev, end_arr_clip_rev = bam_region_read_ends(str(bam_sorted_rev), region, side="both", clipped=True)
        clipped_arr = start_arr_clip_for + end_arr_clip_for + start_arr_clip_rev + end_arr_clip_rev
        return clipped_arr


    def old_predict(self, start:int, end:int, divided_by_coverage:bool = True):
        """
        For test purpose only.
        """
        region = f"{self.chrom}:{start}-{end}"

        coverage_total = self.fetch_coverage(region)
        clipped_arr = self.fetch_clipped(region)
        self.sum_divided = []
        for k in range(len(clipped_arr)):
            if divided_by_coverage:
                if coverage_total[k] > 0:
                    mean = (clipped_arr[k]/coverage_total[k])
                    self.sum_divided.append(mean)
                else:
                    self.sum_divided.append(0)
            else:
                self.sum_divided.append(clipped_arr[k])
        maxindex = np.argmax(self.sum_divided)
        sv_position = start + maxindex
        return sv_position


    def predict_region(self, start:int, end:int):
        """
        Predict the positions of the breakpoints in a region between start and end (corresponding to a cluster).
        The function applies a penalty to the spikes of clipped reads when close to a restriction site.
        """
        region = f"{self.chrom}:{start}-{end}"

        coverage_total = self.fetch_coverage(region)
        clipped_arr = self.fetch_clipped(region)

        self.sum_divided = []
        for k in range(len(clipped_arr)):
            if coverage_total[k] > 0:
                mean = (clipped_arr[k]/coverage_total[k])
                self.sum_divided.append(mean)
            else:
                self.sum_divided.append(0)
        
        # If max falls on restriction site, apply penalty to its score based on the mean
        # score of all the restriction sites in a window around this postion
        restriction_seq = "GATC" # -> Maybe add other restriction sites or allow the user to select the site.
        mean_normal_cov, mean_restrict_cov = self.compute_restriction_ratio(start - 2*self.binsize, end + 2*self.binsize, "GATC")

        # Try to detect at max 4 different positions inside a same cluster.
        max_attempts = 4
        attempted_positions = []
        predictions = []
        for _ in range(max_attempts):
            maxindex = np.argmax(self.sum_divided)
            sv_position = start + maxindex

            if((self.is_close_to_restriction(sv_position, restriction_seq)) and (sv_position not in attempted_positions)):
                attempted_positions.append(sv_position)
                old_score = self.sum_divided[maxindex]
                new_score = old_score*(mean_normal_cov/mean_restrict_cov)
                self.sum_divided[maxindex] = new_score
                print(f"penalty applied at {sv_position} : old {old_score} new {new_score} - [{self.fetch_sequence(start=sv_position-5, end=sv_position)} - {self.fetch_sequence(start=sv_position, end=sv_position + 5)}]")
            else:
                if not self.is_close(sv_position, predictions):
                    print(f"max found at {sv_position} : {self.fetch_sequence(start=sv_position-7, end=sv_position)} - {self.fetch_sequence(start=sv_position, end=sv_position + 7)} ({self.sum_divided[maxindex]})")
                    predictions.append(sv_position)
                    attempted_positions.append(sv_position)
                self.sum_divided[maxindex] = 0
        # If all the attemps end on restriction sites, we can consider that this cluster is a false positive
        return predictions
    
    def is_close_to_restriction(self, position:int, restriction_seq:str):
        max_seq_left = self.fetch_sequence(start=position-len(restriction_seq) - 1, end=position)
        max_seq_right = self.fetch_sequence(start=position, end=position + len(restriction_seq) + 1)
        return (
            max_seq_left[0:4] == restriction_seq or
            max_seq_left[1:5] == restriction_seq or
            max_seq_right[0:4] == restriction_seq or
            max_seq_right[1:5] == restriction_seq
        )
        
    
    def is_close(self, position, tab, trigger=20):
        """
        Tool function returning True if the given position is closer than trigger to
        one of the element of the tab.
        """
        for elem in tab:
            if abs(position-elem) < trigger:
                return True
        return False

    def compute_restriction_ratio(self, start:int, end:int, restriction_seq:str):
        """
        Compute the penalty to apply on restriction spikes based on the mean clipped coverage
        around the detected position.
        """
        chrom_seq = self.seq[self.chrom]
        sequence = chrom_seq.seq[start:end]
        region = f"{self.chrom}:{start}-{end}"
        N = end - start

        coverage = self.fetch_clipped(region)
        normal_cov = []
        restrict_cov = []

        for i in range(4,N):
            quadra = sequence[i-4:i]
            if quadra == restriction_seq:
                restrict_cov.append(coverage[i])
            else:
                normal_cov.append(coverage[i])
        
        mean_normal_cov = np.mean(normal_cov)
        mean_restrict_cov = np.mean(restrict_cov)

        print(f"mean normal clipped = {mean_normal_cov} over {len(normal_cov)}")
        print(f"mean restrict clipped = {mean_restrict_cov} over {len(restrict_cov)}")

        return mean_normal_cov, mean_restrict_cov

    def predict(self):
        """
        Run the prediction for all the detected clusters.
        """
        self.create_clusters()
        SV_bam_predictions = []
        for cluster in self.clusters:
            start = (cluster[0])*self.binsize
            end = (cluster[-1]+1)*self.binsize
            cluster_predictions = self.predict_region(start, end)
            for pred in cluster_predictions:
                SV_bam_predictions.append(pred)

        return SV_bam_predictions

    
    def count_restriction(self):
        chrom_seq = self.seq[self.chrom]
        sequence = chrom_seq.seq
        n = 0
        m = 0
        for i in range(len(sequence)):
            quadra = sequence[i:i+4]
            quinta = sequence[i:i+5]
            if quadra == "GATC":
                print(f"{i} : GATC")
                n += 1
            if quinta[0] == 'G' and quinta[2:5] == "ATC":
                print(f"{i} : {quinta}")
                m += 1
        print(n)
        print(m)
    
    def fetch_sequence(self, start: int, end: int):
        chrom_seq = self.seq[self.chrom]
        sequence = chrom_seq.seq
        return sequence[start:end]



